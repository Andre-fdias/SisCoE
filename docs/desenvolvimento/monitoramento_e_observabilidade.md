# ðŸ› ï¸ DocumentaÃ§Ã£o do Sistema de Monitoramento e Observabilidade do SisCoE

Este documento detalha a arquitetura e a implementaÃ§Ã£o do sistema de versionamento, monitoramento e observabilidade para a aplicaÃ§Ã£o SisCoE, conforme o plano de DevOps solicitado.

## 1. Stack de Ferramentas

-   **Versionamento**: Git, Tags SemÃ¢nticas e Changelog.
-   **Coleta de MÃ©tricas**: `django-prometheus` integrado ao Django.
-   **Armazenamento e Consulta de MÃ©tricas**: Prometheus.
-   **VisualizaÃ§Ã£o e Dashboards**: Grafana.
-   **Alertas**: Prometheus com Alertmanager (configuraÃ§Ã£o inicial).

---

## 2. EstratÃ©gia de Versionamento

Foi definida uma estratÃ©gia de Versionamento SemÃ¢ntico (`MAJOR.MINOR.PATCH`) para governar as releases do projeto, com foco em compliance e auditoria.

> ðŸ“– A documentaÃ§Ã£o completa estÃ¡ disponÃ­vel em: [`docs/desenvolvimento/versionamento.md`](./versionamento.md).

---

## 3. Coleta de MÃ©tricas na AplicaÃ§Ã£o Django

Para expor as mÃ©tricas da aplicaÃ§Ã£o, utilizamos a biblioteca `django-prometheus`.

### 3.1. InstalaÃ§Ã£o

As seguintes dependÃªncias foram adicionadas ao `requirements.txt`:

```txt
django-prometheus
prometheus-client
```

### 3.2. ConfiguraÃ§Ã£o no `settings.py`

O arquivo `backend/settings/base.py` foi modificado para registrar o app e seus middlewares:

-   `'django_prometheus'` foi adicionado ao `INSTALLED_APPS`.
-   Os middlewares `PrometheusBeforeMiddleware` (no inÃ­cio) e `PrometheusAfterMiddleware` (no fim) foram adicionados Ã  lista `MIDDLEWARE` para medir a latÃªncia de todas as requisiÃ§Ãµes.

### 3.3. ExposiÃ§Ã£o do Endpoint de MÃ©tricas

No arquivo `backend/urls.py`, a seguinte rota foi adicionada para que o Prometheus possa acessar as mÃ©tricas:

```python
path('prometheus/', include('django_prometheus.urls')),
```

---

## 4. MÃ©tricas Customizadas (NegÃ³cio e SeguranÃ§a)

AlÃ©m das mÃ©tricas padrÃ£o, criamos mÃ©tricas especÃ­ficas para os requisitos do SisCoE, utilizando o sistema de Sinais (Signals) do Django.

### 4.1. MÃ©tricas de BI do Efetivo

-   **Objetivo**: Monitorar a quantidade de militares por categoria (Ativo, Inativo, etc.) e a taxa de atualizaÃ§Ã£o de suas situaÃ§Ãµes funcionais.
-   **ImplementaÃ§Ã£o**:
    1.  **`backend/efetivo/metrics.py`**: Criado para definir as mÃ©tricas `efetivo_militares_por_categoria_total` (Gauge) e `efetivo_situacao_funcional_updates_total` (Counter).
    2.  **`backend/efetivo/signals.py`**: Criado para definir os *handlers* que atualizam as mÃ©tricas acima sempre que um objeto `CatEfetivo` ou `DetalhesSituacao` Ã© salvo ou deletado.
    3.  **`backend/efetivo/apps.py`**: Modificado para importar e registrar os sinais na inicializaÃ§Ã£o da aplicaÃ§Ã£o.

### 4.2. MÃ©tricas de SeguranÃ§a de Contas

-   **Objetivo**: Monitorar tentativas de login falhas para detectar possÃ­veis ataques.
-   **ImplementaÃ§Ã£o**:
    1.  **`backend/accounts/metrics.py`**: Criado para definir a mÃ©trica `accounts_login_failures_total` (Counter).
    2.  **`backend/accounts/signals.py`**: Criado para definir um *handler* que escuta o sinal `user_login_failed` do Django e incrementa o contador.
    3.  **`backend/accounts/apps.py`**: Modificado para registrar o sinal de seguranÃ§a.

---

## 5. ConfiguraÃ§Ã£o do Prometheus e Alertas

### 5.1. Coleta de MÃ©tricas (`prometheus.yml`)

-   Um arquivo de configuraÃ§Ã£o foi criado em `monitoring/prometheus.yml`.
-   Ele define um *job* chamado `siscoe_django_app` que coleta as mÃ©tricas expostas pelo Django em `localhost:8000/prometheus/metrics`.

### 5.2. Regras de Alerta Inteligente

-   **Objetivo**: Ser notificado proativamente sobre possÃ­veis incidentes de seguranÃ§a.
-   **ImplementaÃ§Ã£o**:
    1.  O arquivo `monitoring/rules/security_alerts.yml` foi criado.
    2.  Nele, foi definida a regra `TaxaElevadaDeFalhasDeLogin`, que entra em estado de alerta se a taxa de falhas de login exceder 5 por minuto.
    3.  O arquivo `monitoring/prometheus.yml` foi atualizado para carregar este novo arquivo de regras.

---

## 6. VisualizaÃ§Ã£o com Grafana

-   **Objetivo**: Ter uma visÃ£o grÃ¡fica e intuitiva das mÃ©tricas de negÃ³cio.
-   **ImplementaÃ§Ã£o**:
    -   Um template de dashboard foi criado em `monitoring/grafana_dashboards/efetivo_dashboard.json`.
    -   Este dashboard pode ser importado no Grafana e contÃ©m painÃ©is para:
        -   Total de Militares Ativos (Gauge).
        -   Taxa de AtualizaÃ§Ã£o de SituaÃ§Ã£o Funcional (GrÃ¡fico de Linha).
        -   DistribuiÃ§Ã£o de Militares por Categoria (GrÃ¡fico de Barras).

---

## 7. Indicador de Versionamento na Interface

Para facilitar a identificaÃ§Ã£o da versÃ£o da aplicaÃ§Ã£o em execuÃ§Ã£o, um indicador de versionamento foi adicionado Ã  interface do usuÃ¡rio.

### 7.1. ImplementaÃ§Ã£o

1.  **`backend/__version__.py`:** Criado para armazenar a string da versÃ£o (ex: `"1.0.0"`).
2.  **`backend/core/context_processors.py`:** Criado para ler o valor de `__version__` e injetÃ¡-lo no contexto de todos os templates como `app_version`.
3.  **`backend/settings/base.py`:** O context processor `backend.core.context_processors.version_indicator` foi adicionado Ã  lista `TEMPLATES['OPTIONS']['context_processors']`.
4.  **`backend/core/templates/landing.html`:** O valor `v{{ app_version }}` foi adicionado ao rodapÃ© da pÃ¡gina, prÃ³ximo Ã  informaÃ§Ã£o de copyright.

---

## 8. Logging Estruturado com ELK Stack

Para uma observabilidade completa, configuramos o Django para gerar logs estruturados (JSON), que podem ser facilmente ingeridos e analisados por um ELK Stack (Elasticsearch, Logstash, Kibana).

### 8.1. ConfiguraÃ§Ã£o no Django

-   **DependÃªncia:** A biblioteca `python-json-logger` foi adicionada ao `requirements.txt`.
-   **`backend/settings/base.py`:** O dicionÃ¡rio `LOGGING` foi atualizado para incluir:
    -   Um novo formatador `json_formatter` usando `python_json_logger.json_logger.JsonFormatter`.
    -   Um novo handler `json_file` que escreve logs JSON no arquivo `logs/app.json.log`.
    -   O handler `json_file` foi adicionado aos `handlers` do logger `root` e do logger `django`.
-   **DiretÃ³rio de Logs:** O diretÃ³rio `logs/` foi criado na raiz do projeto para armazenar os logs JSON.

### 8.2. IntegraÃ§Ã£o com Docker Compose (ELK Stack)

Os seguintes serviÃ§os foram adicionados ao `docker-compose.yml` para orquestrar o ELK Stack:

-   **`elasticsearch`:** Armazena e indexa os logs.
-   **`logstash`:** Processa os logs JSON do Django e os envia para o Elasticsearch.
    -   O volume `./logs:/var/log/django_app` foi montado no serviÃ§o `app` e no `logstash` para que o Logstash possa ler o `app.json.log` gerado pelo Django.
    -   O arquivo de configuraÃ§Ã£o `monitoring/logstash/pipeline/logstash.conf` foi criado para definir o pipeline de ingestÃ£o.
-   **`kibana`:** Fornece a interface de usuÃ¡rio para buscar, visualizar e criar dashboards com os logs.

### 8.3. ConfiguraÃ§Ã£o do Logstash (`monitoring/logstash/pipeline/logstash.conf`)

Este arquivo define o pipeline de ingestÃ£o do Logstash:

```conf
input {
  file {
    path => "/var/log/django_app/app.json.log" # Caminho dentro do container Logstash
    start_position => "beginning"
    sincedb_path => "/dev/null" # Em produÃ§Ã£o, use um caminho persistente.
    codec => json # Informa ao Logstash que o conteÃºdo Ã© JSON
    type => "django_json_log"
  }
}

filter {
  # Adiciona campos Ãºteis para o Kibana
  mutate {
    add_field => { "[@metadata][beat]" => "filebeat" }
    add_field => { "[@metadata][version]" => "7.17.9" }
  }
  # Renomeia o campo 'message' para 'log.original' para compatibilidade com ECS
  if [message] {
    rename => { "message" => "log.original" }
  }
  # Adiciona o nome do serviÃ§o
  mutate {
    add_field => { "service.name" => "siscoe-django" }
  }
  # Adiciona o tipo de log
  mutate {
    add_field => { "event.dataset" => "siscoe.log" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"] # Aponta para o serviÃ§o Elasticsearch no Docker Compose
    index => "siscoe-logs-%{+YYYY.MM.dd}"
  }
  stdout { codec => rubydebug } # Para depuraÃ§Ã£o
}
```

### 8.4. Como Usar o ELK Stack

1.  **Inicie os serviÃ§os Docker:**
    ```bash
    docker-compose up -d
    ```
2.  **Acesse o Kibana:** `http://localhost:5601`
3.  **Crie um Index Pattern:** No Kibana, vÃ¡ para "Stack Management" -> "Index Patterns" e crie um novo com o nome `siscoe-logs-*` e selecione `@timestamp` como campo de tempo.
4.  **Visualize:** Em "Analytics" -> "Discover", selecione o index pattern para ver seus logs estruturados.


